<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://lposti.github.io/MLPages/feed.xml" rel="self" type="application/atom+xml" /><link href="https://lposti.github.io/MLPages/" rel="alternate" type="text/html" /><updated>2022-06-16T04:54:05-05:00</updated><id>https://lposti.github.io/MLPages/feed.xml</id><title type="html">An Astronomerâ€™s perspective on Deep Learning</title><subtitle>Notes and notebooks of a pro Astronomer diving deep into the wonders of machine learning</subtitle><entry><title type="html">Variational Autoencoder: learning an underlying distribution and generating new data</title><link href="https://lposti.github.io/MLPages/neural%20network/autoencoder/variational%20autoencoder/basics/jupyter/2022/06/15/variational_autoencoder_rotcurves.html" rel="alternate" type="text/html" title="Variational Autoencoder: learning an underlying distribution and generating new data" /><published>2022-06-15T00:00:00-05:00</published><updated>2022-06-15T00:00:00-05:00</updated><id>https://lposti.github.io/MLPages/neural%20network/autoencoder/variational%20autoencoder/basics/jupyter/2022/06/15/variational_autoencoder_rotcurves</id><author><name>Lorenzo Posti</name></author><category term="neural network" /><category term="autoencoder" /><category term="variational autoencoder" /><category term="basics" /><category term="jupyter" /><summary type="html"><![CDATA[Constructing an autoencoder that learns the underlying distribution of the input data, generated from a multi-dimensional smooth function `f=f(x_1,x_2,x_3,x_4)`. This can be used to generate new data, sampling from the learned distribution]]></summary></entry><entry><title type="html">Understanding how basic linear NNs handle non-linearities</title><link href="https://lposti.github.io/MLPages/neural%20network/basics/bayesian/mcmc/jupyter/2022/06/15/neurons_non-linearities.html" rel="alternate" type="text/html" title="Understanding how basic linear NNs handle non-linearities" /><published>2022-06-15T00:00:00-05:00</published><updated>2022-06-15T00:00:00-05:00</updated><id>https://lposti.github.io/MLPages/neural%20network/basics/bayesian/mcmc/jupyter/2022/06/15/neurons_non-linearities</id><author><name>Lorenzo Posti</name></author><category term="neural network" /><category term="basics" /><category term="bayesian" /><category term="MCMC" /><category term="jupyter" /><summary type="html"><![CDATA[A deep exploration, an visualization, of how a single-layer linear neural network (NN) is able to approximate non linear behaviours with a just handful of neurons and the magic of activation functions.]]></summary></entry><entry><title type="html">Autoencoder represents a multi-dimensional smooth function</title><link href="https://lposti.github.io/MLPages/neural%20network/autoencoder/basics/jupyter/2022/06/15/autoencoder_rotcurves.html" rel="alternate" type="text/html" title="Autoencoder represents a multi-dimensional smooth function" /><published>2022-06-15T00:00:00-05:00</published><updated>2022-06-15T00:00:00-05:00</updated><id>https://lposti.github.io/MLPages/neural%20network/autoencoder/basics/jupyter/2022/06/15/autoencoder_rotcurves</id><author><name>Lorenzo Posti</name></author><category term="neural network" /><category term="autoencoder" /><category term="basics" /><category term="jupyter" /><summary type="html"><![CDATA[Setting up a simple `Autoencoder` neural network to reproduce a dataset obtained by sampling a multi-dimensional smooth function `f=f(x_1,x_2,x_3,x_4)`. As an example I'm using a disc+halo rotation curve model where both components are described by 2-parameters circular velocities]]></summary></entry><entry><title type="html">Ground-up construction of a simple neural network</title><link href="https://lposti.github.io/MLPages/neural%20network/basics/jupyter/2022/06/15/NN_from_scratch.html" rel="alternate" type="text/html" title="Ground-up construction of a simple neural network" /><published>2022-06-15T00:00:00-05:00</published><updated>2022-06-15T00:00:00-05:00</updated><id>https://lposti.github.io/MLPages/neural%20network/basics/jupyter/2022/06/15/NN_from_scratch</id><author><name>Lorenzo Posti</name></author><category term="neural network" /><category term="basics" /><category term="jupyter" /><summary type="html"><![CDATA[Constructing a simple multi-layered neural network (NN) from scratch using pure `python` and a bit of `pytorch`. This is mostly my personal re-writing of the fantastic lesson 1 of the `fast.ai` course Part 2]]></summary></entry><entry><title type="html">Fastpages Notebook Blog Post</title><link href="https://lposti.github.io/MLPages/jupyter/2020/02/20/test.html" rel="alternate" type="text/html" title="Fastpages Notebook Blog Post" /><published>2020-02-20T00:00:00-06:00</published><updated>2020-02-20T00:00:00-06:00</updated><id>https://lposti.github.io/MLPages/jupyter/2020/02/20/test</id><author><name></name></author><category term="jupyter" /><summary type="html"><![CDATA[A tutorial of fastpages for Jupyter notebooks.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://lposti.github.io/MLPages/images/chart-preview.png" /><media:content medium="image" url="https://lposti.github.io/MLPages/images/chart-preview.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>