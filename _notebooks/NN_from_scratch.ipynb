{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5246bd20",
   "metadata": {},
   "source": [
    "# \"Ground-up construction of a simple neural network\"\n",
    "> \"Constructing a simple multi-layered neural network (NN) from scratch using pure `python` and a bit of `pytorch`. This is mostly my personal re-writing of the fantastic lesson 1 of the [fast.ai](https://www.fast.ai/) [course Part 2](https://course19.fast.ai/videos/?lesson=8)\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Lorenzo Posti\n",
    "- categories: [neural network, basics, jupyter]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dd0443",
   "metadata": {},
   "source": [
    "## Linear layers and activation functions from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08453178",
   "metadata": {},
   "source": [
    "When approaching the study of a new subject I find it extremely useful to get my hands dirty and play around with the stuff I'm learning, in order to cement the knowledge that I'm passively acquiring reading or listening to a lecture. In the case of deep learning, before starting to use massively the superb `python` libraries available, e.g. `pytorch` or `fast.ai`, I think it's critical to build a simple NN from scratch.\n",
    "\n",
    "The bits required are just linear operations, e.g. matrix multiplications, functional composition and the chain rule to get the derivatives during back-propagation. All of this sounds not terrible at all, so we just need a bit of organization to glue all the pieces together.\n",
    "\n",
    "We take inspiration from the `pytorch` library and we start by building an abstract `Module` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecef2038",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "import numpy as np\n",
    "from torch import tensor\n",
    "from torch import nn\n",
    "import random\n",
    "\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1297f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module():\n",
    "    \"\"\" abstract class: on call it saves the input and output, and it returns the output \"\"\"\n",
    "    def __call__(self, *args):\n",
    "        self.args = args\n",
    "        self.out = self.forward(*args)\n",
    "        return self.out\n",
    "    \n",
    "    def forward(self): raise Exception('not implemented')\n",
    "    def backward(self): self.bwd(self.out, *self.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a91a91",
   "metadata": {},
   "source": [
    "When called, `Module` stores the input and the output items and just returns the output which is defined by the method `forward`, which needs to be overridden by the derived class. Another method, `backward`, will be needed to return the derivative of the function and to implement back-propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53f69f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ac16b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e18a3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
